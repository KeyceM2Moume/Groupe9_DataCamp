{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebab0abd-5d6e-4230-9c38-f20bcff51d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Importation des librairies nécessaires au scraping\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685a04e2-2259-4073-92db-19695062ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# URL de la page de l'application Spotify sur le Google Play Store\n",
    "url = 'https://play.google.com/store/apps/details?id=com.spotify.music'\n",
    "# Liste pour stocker les avis extraits\n",
    "reviews = [] \n",
    "    \n",
    "try:\n",
    "    # Envoi de la requête HTTP pour récupérer le contenu HTML de la page\n",
    "    response = requests.get(url)\n",
    "    # Parsing du HTML avec BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "    # Recherche de la div contenant les avis (vérifiez les sélecteurs selon la structure HTML réelle)\n",
    "    review_container = soup.find('div', class_='h3YV2d', attrs={'data-g-id': 'reviews'})\n",
    "    print(review_container)\n",
    "except Exception as e:\n",
    "    # Gestion des erreurs lors de la requête HTTP\n",
    "    print(f\"Erreur de requête : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d1e18c-70db-43d2-81e3-68b001b999ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la page de l'application Spotify sur le Google Play Store\n",
    "url = 'https://play.google.com/store/apps/details?id=com.spotify.music'\n",
    "# Liste pour stocker les avis extraits\n",
    "reviews = [] \n",
    "    \n",
    "try:\n",
    "    # Envoi de la requête HTTP pour récupérer le contenu HTML de la page\n",
    "    response = requests.get(url)\n",
    "    # Parsing du HTML avec BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "    # Recherche de la div contenant les avis (vérifiez les sélecteurs selon la structure HTML réelle)\n",
    "    review_container = soup.find('div', class_='Jwxk6d', attrs={'data-g-id': 'reviews'})\n",
    "    review_container\n",
    "    \n",
    "    if review_container:\n",
    "        # Récupération de toutes les divs représentant les avis individuels\n",
    "        individual_reviews = review_container.find_all('div', recursive=True)\n",
    "        \n",
    "        for review in individual_reviews:\n",
    "            # Extraction des détails de chaque avis\n",
    "            try:\n",
    "                # Note de l'utilisateur (étoiles)\n",
    "                rating = review.find('div', aria_label=True)\n",
    "                # Texte du commentaire\n",
    "                review_text = review.find('div', class_='h3YV2d')\n",
    "                # Date de l'avis\n",
    "                date = review.find('span', class_='bp9Aid')\n",
    "                # Nombre de \"likes\" pour l'avis\n",
    "                likes = review.find('div', {'data-original-thumbs-up-count': True})\n",
    "\n",
    "                # Vérification que la note et le commentaire existent\n",
    "                if rating and review_text:\n",
    "                    # Structuration des données extraites dans un dictionnaire\n",
    "                    review_data = {\n",
    "                            'note': rating.get('aria-label', 'N/A'),\n",
    "                            'commentaire': review_text.text.strip(),\n",
    "                            'date': date.text.strip() if date else 'N/A',\n",
    "                            'likes' : likes.get('data-original-thumbs-up-count', '0') if likes else '0'\n",
    "                    }\n",
    "                    \n",
    "                    # Ajout des données de l'avis à la liste\n",
    "                    reviews.append(review_data)\n",
    "                    \n",
    "            # Gestion des erreurs lors de l'extraction des données d'un avis   \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction d'une review: {e}\")\n",
    "        \n",
    "    else:\n",
    "        # Message si la div contenant les avis n'a pas été trouvée\n",
    "        print(\"Conteneur de reviews non trouvé\")\n",
    "except Exception as e:\n",
    "    # Gestion des erreurs lors de la requête HTTP\n",
    "    print(f\"Erreur de requête : {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe4093f-d940-4a5e-8f52-b62a0f651bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La liste 'reviews' est vide ou n'a pas été remplie correctement.\n"
     ]
    }
   ],
   "source": [
    "if reviews:  # Vérifie si la liste n'est pas vide\n",
    "    for i, review in enumerate(reviews[:10], start=1):\n",
    "        if review:  # Vérifie si chaque élément n'est pas None\n",
    "            print(f\"Review {i}: {review}\")\n",
    "        else:\n",
    "            print(f\"Review {i}: Null\")\n",
    "else:\n",
    "    print(\"La liste 'reviews' est vide ou n'a pas été remplie correctement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c437c2-441a-48af-96c5-5c0346a66ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
